{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model Evaluation\n",
    "\n",
    "## Examples:\n",
    "\n",
    "Imagine you're bringing coffee to meeting, and you need to predict whether each person at the meeting will want a coffee or not. Which metric should you choose? It depends\n",
    "\n",
    "Outcomes:\n",
    "\n",
    "- FP: Buy a coffee for someone who won't drink it\n",
    "- FN: Don't buy a coffee for someone who wanted one\n",
    "- TP: Buy a coffee for someone who will drink it\n",
    "- TN: Don't buy a coffee for someone who wouldn't drink it anyway\n",
    "\n",
    "Scenarios\n",
    "\n",
    "- lola: really good coffee, but super expensive\n",
    "    - cost of a FP is higher than FN\n",
    "    - precision is better here because buying a cup of coffee for someone who won't drink it is expensive\n",
    "    - We want to be sure about our positive predictions\n",
    "- taco cabana: bad coffee, but cheap\n",
    "    - cost of a FN is higher than FP\n",
    "    - recall because the coffee is cheap, its not bad to buy a cheap coffee for someone who won't drink it; worse to not get someone coffee who wanted it\n",
    "- meeting with super important client\n",
    "    - cost of FN is higher, because they might be offended if we dont' get them coffee\n",
    "    - cost of FN == not signing a contract\n",
    "    - recall\n",
    "\n",
    "What if we just don't buy coffee or buy coffee for everyone? Baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Exercise\n",
    "\n",
    "**Scenario: Build a classifier to predict whether a given face should unlock the iPhone.**\n",
    "\n",
    "**- What is the positive and negative case?**\n",
    "- positive case : unlock the iPhone with the correct face\n",
    "- negative case : unlock the iPhone with the incorrect face\n",
    "\n",
    "**- What are the possible outcomes?**\n",
    "\n",
    "- FP: unlock the phone when it was not the correct face\n",
    "- FN: do not unlock the iPhone when it is the correct face\n",
    "- TP: unlock the iPhone with the correct face\n",
    "- TN: do not unlock the phon when it is the incorrect face\n",
    "\n",
    "\n",
    "**- What are the costs of the outcomes?**\n",
    "- cost of FP is higher because everyone can access to the iPhone\n",
    "\n",
    "**- Which metric should we use?**\n",
    "- precision\n",
    "\n",
    "\n",
    "**Scenario: Predict whether an email is spam or not. Emails marked as spam skip the inbox and go to the spam folder.**\n",
    "\n",
    "**- What is the positive and negative case?**\n",
    "- positive case : emails that really are spam go to the spam folder\n",
    "- negative case: emails that are not spam are to the spam folder \n",
    "\n",
    "**- What are the possible outcomes?**\n",
    "- FP: email (not a spam) goes to the spam folder\n",
    "- FN: \n",
    "- TP: \n",
    "- TN: \n",
    "**- What are the costs of the outcomes?**\n",
    "**- Which metric should we use?**\n",
    "\n",
    "Scenario: Predict whether an email is a phishing attempt. When we predict positive, show an additional banner warning the user that this might be a phishing email.\n",
    "\n",
    "- What is the positive and negative case?\n",
    "- What are the possible outcomes?\n",
    "- What are the costs of the outcomes?\n",
    "- Which metric should we use?\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coffee</td>\n",
       "      <td>no coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no coffee</td>\n",
       "      <td>no coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>no coffee</td>\n",
       "      <td>no coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>coffee</td>\n",
       "      <td>no coffee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual prediction\n",
       "0     coffee  no coffee\n",
       "1  no coffee  no coffee\n",
       "2  no coffee     coffee\n",
       "3     coffee     coffee\n",
       "4     coffee     coffee\n",
       "5     coffee     coffee\n",
       "6  no coffee  no coffee\n",
       "7     coffee  no coffee"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'actual': ['coffee', 'no coffee', 'no coffee', 'coffee', 'coffee', 'coffee', 'no coffee', 'coffee'],\n",
    "    'prediction': ['no coffee', 'no coffee', 'coffee', 'coffee', 'coffee', 'coffee', 'no coffee', 'no coffee'],\n",
    "})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>actual</th>\n",
       "      <th>coffee</th>\n",
       "      <th>no coffee</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coffee</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no coffee</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "actual      coffee  no coffee\n",
       "prediction                   \n",
       "coffee           3          1\n",
       "no coffee        2          2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df.prediction, df.actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TP: predicted coffee + actual is coffee\n",
    "- FP: predicted coffee, but they didn't like coffee\n",
    "- FN: predicted no coffee, but really they liked coffee\n",
    "- TN: predicted no coffee, actual no coffee\n",
    "\n",
    "Note:\n",
    "\n",
    "- our choice of positive and negative is arbitrary\n",
    "- the labels / layout of the confusion matrix varies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "- **accuracy**: (TP + TN) / (TP + TN + FP + FN)\n",
    "    - (3 + 2) / (3 + 1 + 2 +2) = 62.5%\n",
    "- **precision**: TP / (TP + FP)\n",
    "    - 3 / (3 + 1) = 75%\n",
    "    - FP is more costly than FN\n",
    "- **recall**: TP / (TP + FN)\n",
    "    - 3 / (3 + 2) = 60%\n",
    "    - FN is more costly than FP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: rgba(0, 150, 0, .25); padding: 1em 3em;\">\n",
    "    <p style=\"font-weight: bold\">Sidebar: Baseline Models</p>\n",
    "    <p>A <em>baseline model</em> is a model that we can compare to in order to see if the models we are creating are worthwhile.</p>\n",
    "    <p>Depending on the context, this can mean either an existing rule-based model created with domain knowlege, or a model that makes predictions without any knowledge of the independent variables.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coffee       5\n",
       "no coffee    3\n",
       "Name: actual, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.actual.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['baseline'] = 'coffee'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>prediction</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>coffee</td>\n",
       "      <td>no coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no coffee</td>\n",
       "      <td>no coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no coffee</td>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>no coffee</td>\n",
       "      <td>no coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>coffee</td>\n",
       "      <td>no coffee</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      actual prediction baseline\n",
       "0     coffee  no coffee   coffee\n",
       "1  no coffee  no coffee   coffee\n",
       "2  no coffee     coffee   coffee\n",
       "3     coffee     coffee   coffee\n",
       "4     coffee     coffee   coffee\n",
       "5     coffee     coffee   coffee\n",
       "6  no coffee  no coffee   coffee\n",
       "7     coffee  no coffee   coffee"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Metric Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1     True\n",
       "2    False\n",
       "3     True\n",
       "4     True\n",
       "5     True\n",
       "6     True\n",
       "7    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.actual == df.prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model accuracy\n",
    "(df.actual == df.prediction).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseline accuracy\n",
    "(df.actual == df.baseline).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      actual prediction baseline\n",
      "2  no coffee     coffee   coffee\n",
      "3     coffee     coffee   coffee\n",
      "4     coffee     coffee   coffee\n",
      "5     coffee     coffee   coffee\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision -- how good are our positive predictions\n",
    "# precision -- model performance | pred +\n",
    "subset = df[df.prediction == 'coffee']\n",
    "print(subset)\n",
    "(subset.prediction == subset.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   actual prediction baseline\n",
      "0  coffee  no coffee   coffee\n",
      "3  coffee     coffee   coffee\n",
      "4  coffee     coffee   coffee\n",
      "5  coffee     coffee   coffee\n",
      "7  coffee  no coffee   coffee\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall -- how often do we get the actual positive cases\n",
    "# recall -- model performance | actual +\n",
    "subset = df[df.actual == 'coffee']\n",
    "print(subset)\n",
    "(subset.prediction == subset.actual).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What will the precision and recall of our baseline model that always predicts + be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      actual prediction baseline\n",
      "0     coffee  no coffee   coffee\n",
      "1  no coffee  no coffee   coffee\n",
      "2  no coffee     coffee   coffee\n",
      "3     coffee     coffee   coffee\n",
      "4     coffee     coffee   coffee\n",
      "5     coffee     coffee   coffee\n",
      "6  no coffee  no coffee   coffee\n",
      "7     coffee  no coffee   coffee\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision\n",
    "subset = df[df.baseline == 'coffee']\n",
    "print(subset)\n",
    "(subset.baseline == subset.actual).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   actual prediction baseline\n",
      "0  coffee  no coffee   coffee\n",
      "3  coffee     coffee   coffee\n",
      "4  coffee     coffee   coffee\n",
      "5  coffee     coffee   coffee\n",
      "7  coffee  no coffee   coffee\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall\n",
    "subset = df[df.actual == 'coffee']\n",
    "print(subset)\n",
    "(subset.baseline == subset.actual).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does \"positive\" mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "positive: coffee\n",
      "\n",
      "         | accuracy | recall | precision\n",
      "         | -------- | ------ | ---------         \n",
      "   model |    62.5% |  60.0% |     75.0%\n",
      "baseline |    62.5% | 100.0% |     62.5%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "positive = 'coffee'\n",
    "\n",
    "# accuracy -- overall hit rate\n",
    "model_accuracy = (df.prediction == df.actual).mean()\n",
    "baseline_accuracy = (df.baseline == df.actual).mean()\n",
    "\n",
    "# precision -- how good are our positive predictions?\n",
    "# precision -- model performance | predicted positive\n",
    "subset = df[df.prediction == positive]\n",
    "model_precision = (subset.prediction == subset.actual).mean()\n",
    "subset = df[df.baseline == positive]\n",
    "baseline_precision = (subset.baseline == subset.actual).mean()\n",
    "\n",
    "# recall -- how good are we at detecting actual positives?\n",
    "# recall -- model performance | actual positive\n",
    "subset = df[df.actual == positive]\n",
    "model_recall = (subset.prediction == subset.actual).mean()\n",
    "baseline_recall = (subset.baseline == subset.actual).mean()\n",
    "\n",
    "\n",
    "print(f'''\n",
    "positive: {positive}\n",
    "\n",
    "         | accuracy | recall | precision\n",
    "         | -------- | ------ | ---------         \n",
    "   model | {model_accuracy:8.1%} | {model_recall:6.1%} | {model_precision:9.1%}\n",
    "baseline | {baseline_accuracy:8.1%} | {baseline_recall:6.1%} | {baseline_precision:9.1%}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
